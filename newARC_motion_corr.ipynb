{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DARPA MSIT Analysis Tutorial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Behavior Analysis\n",
    "This section covers the behavioral analysis for MSIT. This section can only be run of the subject's behavioral file has been transferred to Lilli (/space/lilli/1/users/DARPA-Behavior/msit/csv)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1a: Preprocess and save MSIT data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-21T17:59:29.262332Z",
     "start_time": "2018-08-21T17:59:27.509833Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pylab as plt\n",
    "from pandas import read_csv\n",
    "from scipy.io import savemat\n",
    "from scipy.stats import probplot\n",
    "\n",
    "#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "### Define parameters.\n",
    "#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "\n",
    "## I/O parameters.\n",
    "subject = 'hc042'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-13T20:01:59.188389Z",
     "start_time": "2018-07-13T20:01:59.031004Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done.\n"
     ]
    }
   ],
   "source": [
    "## Rejection parameters.\n",
    "missing = 0.10           # Threshold of fraction missing data for rejection.\n",
    "accuracy = 0.80          # Threshold of fraction accuracy data for rejection.\n",
    "fastRT = 0.3             # Threshold for reaction times, below which are censored.\n",
    "    \n",
    "#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "### Load and preprocess data.\n",
    "#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "\n",
    "## Load data.\n",
    "csv_dir = '/autofs/space/lilli/1/users/DARPA-Behavior/msit/csv'\n",
    "csv = read_csv(os.path.join(csv_dir, '%s_msit_mri-1' %subject))\n",
    "csv = csv[csv.Condition!=0].reset_index(drop=True) # Remove rest trials.\n",
    "\n",
    "## Update trial numbers.\n",
    "csv.Trial = np.arange(csv.shape[0]) + 1\n",
    "\n",
    "## Set reaction times below fastRT threshold as missing.\n",
    "csv.ResponseAccuracy = np.where(csv.ResponseTime < fastRT, 99, csv.ResponseAccuracy)\n",
    "csv.ResponseTime = np.where(csv.ResponseTime < fastRT, np.nan, csv.ResponseTime)\n",
    "\n",
    "## Set all 99s to NaNs in RTs.\n",
    "csv.ResponseTime = np.where(csv.ResponseTime==99, np.nan, csv.ResponseTime)\n",
    "csv.ResponseAccuracy = np.where(csv.ResponseAccuracy==99, np.nan, csv.ResponseAccuracy)\n",
    "csv['Missing'] = np.isnan(csv.ResponseTime).astype(int)\n",
    "\n",
    "## Transform RTs. Add Intercept.\n",
    "csv['logRT'] = np.log(csv.ResponseTime)\n",
    "csv['Intercept'] = 1\n",
    "\n",
    "## Reduce CSV to columns of interest.\n",
    "csv = csv[['Trial','Intercept','Condition','ResponseTime','logRT','ResponseAccuracy','Missing','StimOnset']]\n",
    "csv.columns = ['Trial','Intercept','Interference','RT','logRT','Accuracy','Missing','Onset']\n",
    "csv['Interference'] = np.where(csv['Interference']==2,1,0)\n",
    "\n",
    "#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "### Check quality. Save.\n",
    "#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "if csv.RT.isnull().mean() > missing: \n",
    "    print 'Excluding %s: missing trials.' %subject\n",
    "elif csv.Accuracy.mean() < accuracy: \n",
    "    print 'Excluding %s: incorrect trials.' %subject\n",
    "else:\n",
    "    mdict = dict()\n",
    "    for col in csv.columns: mdict[col] = csv[col].as_matrix()\n",
    "    savemat('/autofs/space/lilli_001/users/DARPA-Scripts/tutorials/\\\n",
    "    darpa_msit_ecr_pipeline_EH/behavior/%s_msit_raw.mat' %subject, mdict)\n",
    "    \n",
    "print 'Done.'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1b: Run State Space Model\n",
    "\n",
    "The MSIT state space model is as follows:\n",
    "\n",
    "$$\n",
    "RT(k) = \\beta_0 + \\beta_1 * Interference + X_{ss}(k)\n",
    "$$\n",
    "where\n",
    "$$\n",
    "X_{ss}(k) = X_{ss}(k - 1) + W\n",
    "$$\n",
    "\n",
    "Interference is 1 if the current trial k is an incongruent trial and 0 if it is a congruent trial.\n",
    "\n",
    "Open Matlab and see the msit_sswrapper.m script."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1c: Visualize Results of State Space Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-16T18:18:08.787055Z",
     "start_time": "2018-07-16T18:18:07.243282Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pylab as plt\n",
    "import seaborn as sns\n",
    "from pandas import read_csv\n",
    "from scipy.io import loadmat\n",
    "sns.set_style('white')\n",
    "sns.set_context('paper', font_scale=2.25)\n",
    "\n",
    "#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "### Define parameters.\n",
    "#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "\n",
    "subject = 'hc042'\n",
    "\n",
    "#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "### Main loop.\n",
    "#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "\n",
    "def normalize(arr): return (arr - arr.min()) / (arr.max() - arr.min())\n",
    "behavior_dir = '/autofs/space/lilli_001/users/DARPA-Behavior/'\n",
    "\n",
    "fig = plt.figure(figsize=(12,4))\n",
    "mat = loadmat('/autofs/space/lilli_001/users/DARPA-Scripts/tutorials/\\\n",
    "darpa_msit_ecr_pipeline_EH/behavior/%s_msit_ss.mat' %subject)\n",
    "\n",
    "#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "### Plot MSIT RT barplot.\n",
    "#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "\n",
    "## Load and prepare behavior data.\n",
    "df = read_csv(os.path.join(behavior_dir,'msit','csv','%s_msit_mri-1' %subject))\n",
    "df = df[df.ResponseAccuracy!=99].reset_index(drop=True)\n",
    "df['zRT'] = (df.ResponseTime - df.ResponseTime.mean()) / df.ResponseTime.std()\n",
    "gb = df.groupby('Conflict').zRT.mean()\n",
    "\n",
    "## Plot z-scored reaction times.\n",
    "ax = plt.subplot2grid((1,4),(0,0))    \n",
    "ax.bar(range(len(gb)), gb, width=0.9, color='#41ab5d')\n",
    "ax.set_xlim(-0.1)\n",
    "ax.set_xticks(np.arange(len(gb))+0.45)\n",
    "ax.hlines(0,-0.1,len(gb))\n",
    "ax.set_xticklabels(['CC','IC','CI','II'])\n",
    "ax.set_ylabel('z-scored RT')\n",
    "\n",
    "#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "### Plot timeseries of reaction times.\n",
    "#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "\n",
    "## Initialize plot.\n",
    "ax = plt.subplot2grid((1,4),(0,1),colspan=3)    \n",
    "colors = np.where(mat['Interference'].squeeze(), '#ca0020', '#0571b0')\n",
    "markers = np.where(mat['Accuracy'],'o','s').squeeze()\n",
    "\n",
    "## Plot lines/scatter points.\n",
    "rt = mat['RT'].squeeze()\n",
    "ax.plot(mat['Trial'].squeeze(), rt, color='k', linewidth=2, alpha=0.4)\n",
    "for x,y,c,m in zip(mat['Trial'].squeeze(), rt, colors, markers): \n",
    "    ax.scatter(x,y,s=40,marker=m,color=c)\n",
    "for color, label in zip(['#0571b0', '#ca0020'], ['C','I']): \n",
    "    ax.scatter([],[], s=60, color=color, label=label)\n",
    "\n",
    "## Add flourishes.\n",
    "ax.set_xlim(0,196)\n",
    "ax.set_xlabel('Trial Number', fontsize=16)\n",
    "ax.set_ylabel('Reaction Time', fontsize=18)\n",
    "\n",
    "#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "### Plot state space regressor.\n",
    "#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "\n",
    "## Assemble state space regressors.\n",
    "ss_outputs = np.expand_dims(np.array([np.concatenate(arr) for arr in mat['XSmt']]).squeeze(),1)\n",
    "\n",
    "## Scale state space regressor.\n",
    "ss = normalize(ss_outputs.squeeze())\n",
    "ss *= np.nanmax(rt) - np.nanmin(rt)\n",
    "ss += np.nanmin(rt)\n",
    "\n",
    "## Plot state-space.\n",
    "ax.plot(mat['Trial'].squeeze(), ss.T, linewidth=2.5, color='k', label='ssBias', alpha=0.7)        \n",
    "\n",
    "## Add flourishes.\n",
    "ax.legend(loc=7, bbox_to_anchor=(1.175,0.5), frameon=False, borderpad=0, handlelength=0.5, handletextpad=0.5)\n",
    "\n",
    "sns.despine()\n",
    "plt.suptitle('%s MSIT' %subject.upper(), y=0.99, fontsize=24)\n",
    "plt.subplots_adjust(left=0.1,right=0.9,bottom=0.15, wspace=0.75)\n",
    "f = '/autofs/space/lilli_001/users/DARPA-Scripts/tutorials/darpa_msit_ecr_pipeline_EH/\\\n",
    "plots/behavior/%s_msit_behavior.png' %subject\n",
    "plt.savefig(f, dpi=180)\n",
    "plt.close('all')\n",
    "    \n",
    "print 'Done.'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Generate Task Regressors\n",
    "This section creates the task regressors for the first level analysis of DARPA MSIT. The task regressor files will be saved for first-level analysis in the subject's FSFAST folder in: /autofs/space/lilli_004/users/DARPA-MSIT.\n",
    "\n",
    "The ssBias (this is the state space term from the formulation above) was used for the H9.1 milestone analyses. The interference beta was used for the H9.3 milestone comparisons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-16T18:54:52.339784Z",
     "start_time": "2018-07-16T18:54:51.955402Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from scipy.io import loadmat\n",
    "from scipy.special import gammaln\n",
    "\n",
    "#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "### Define parameters.\n",
    "#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "\n",
    "subject = 'hc042'\n",
    "    \n",
    "## Define contrasts.\n",
    "conditions = ['Intercept','Interference','ssBias']\n",
    "n_conditions = len(conditions)\n",
    "\n",
    "## Timing information.\n",
    "n_acq = 228\n",
    "tr = 1.75\n",
    "sfreq = 1e2\n",
    "\n",
    "#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "### Define useful functions.\n",
    "#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "\n",
    "def spm_hrf(RT, P=None, fMRI_T=16):\n",
    "    p = np.array([6, 16, 1, 1, 6, 0, 32], dtype=float)\n",
    "    if P is not None:\n",
    "        p[0:len(P)] = P\n",
    "\n",
    "    _spm_Gpdf = lambda x, h, l: np.exp(h * np.log(l) + (h - 1) * np.log(x) - (l * x) - gammaln(h))\n",
    "    # modelled hemodynamic response function - {mixture of Gammas}\n",
    "    dt = RT / float(fMRI_T)\n",
    "    u = np.arange(0, int(p[6] / dt + 1)) - p[5] / dt\n",
    "    with np.errstate(divide='ignore'):  # Known division-by-zero\n",
    "        hrf = _spm_Gpdf(u, p[0] / p[2], dt / p[2]) - _spm_Gpdf(u, p[1] / p[3],\n",
    "                                                               dt / p[3]) / p[4]\n",
    "    idx = np.arange(0, int((p[6] / RT) + 1)) * fMRI_T\n",
    "    hrf = hrf[idx]\n",
    "    hrf = hrf / np.sum(hrf)\n",
    "    return hrf\n",
    "\n",
    "#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "### Initialize regressors.\n",
    "#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~# \n",
    "\n",
    "## Setup timing information.\n",
    "total_time = n_acq * tr\n",
    "times = np.arange(0, total_time+1./sfreq, 1./sfreq)\n",
    "n_times = times.shape[0]\n",
    "\n",
    "## Initialize boxcars.\n",
    "neural_signal = np.zeros((n_conditions,n_times))\n",
    "\n",
    "## Extract information.\n",
    "mat = loadmat('/autofs/space/lilli_001/users/DARPA-Scripts/tutorials/darpa_msit_ecr_pipeline_EH/behavior/%s_msit_ss.mat' %subject)\n",
    "Interference = mat['Interference'].squeeze()\n",
    "ssBias = np.concatenate(mat['XSmt'].squeeze()).squeeze()\n",
    "TrialOnset = mat['Onset'].squeeze()\n",
    "\n",
    "#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "### Generate boxcars.\n",
    "#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~# \n",
    "\n",
    "for onset, i, ss in zip(TrialOnset,Interference,ssBias): \n",
    "    mask = (times >= onset) & (times <= onset + 1.75)\n",
    "    neural_signal[0,mask] += 1         # Intercept\n",
    "    neural_signal[1,mask] += i         # Interference\n",
    "    neural_signal[2,mask] += ss        # State-space\n",
    "\n",
    "#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "### Generate fMRI regressors.\n",
    "#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~# \n",
    "\n",
    "## Perform convolution.\n",
    "hrf = spm_hrf(1./sfreq)\n",
    "bold_signal = np.apply_along_axis(np.convolve, 1, neural_signal, v=hrf)\n",
    "bold_signal = bold_signal[:,:neural_signal.shape[-1]] # Set back to original length.\n",
    "\n",
    "## Downsample to start of TR.\n",
    "tr_onsets = np.insert( np.cumsum( np.ones(n_acq-1)*tr ), 0, 0 )\n",
    "ds = np.in1d(times, tr_onsets)\n",
    "if not ds.sum() == n_acq: raise ValueError('Oh noes!')\n",
    "bold_signal = bold_signal[:,ds]\n",
    "\n",
    "## Normalize regressors. [See Calhoun et al. (2004)]\n",
    "## First we normalize [Intercept, DDB, Valence] such that the sum\n",
    "## of their timeseries squared is equal to 1.\n",
    "sums = np.power(bold_signal,2).sum(axis=1)\n",
    "bold_signal = (bold_signal.T / np.sqrt(sums)).T\n",
    "\n",
    "#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "### Save regressors.\n",
    "#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~# \n",
    "\n",
    "out_dir = '/autofs/space/lilli_004/users/DARPA-MSIT/%s/msit_001/001' %subject\n",
    "for arr, label in zip(bold_signal, conditions):\n",
    "\n",
    "    f = '%s/msit_EH_V1.%s.par' %(out_dir,label)\n",
    "    try: np.savetxt(f, arr[:,np.newaxis], fmt='%s')\n",
    "    except IOError: pass\n",
    "\n",
    "print 'Done.'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Generate Nuisance Regressors\n",
    "This section creates custom nuisance regressors for use in the first-level analysis. Specifically, the script creates (1) demeaned, detrended, and orthogonalized motion regressors that explain 90% of the variance in the motion; and (2) the timepoints to censor based on functional displacement (FD; Power et al. 2012, 2014) values. Users will specify which FD thresholds to use to create subject-specific timepoint censoring files to be used in the first level analyses. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-21T19:59:59.181516Z",
     "start_time": "2018-08-21T19:59:59.087862Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from pandas import read_csv\n",
    "from scipy.signal import detrend\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# subjlist = ['hc001','hc002','hc003', 'hc004', 'hc005', 'hc006', 'hc007', 'hc008', 'hc009', 'hc010', \\\n",
    "#            'hc011', 'hc012', 'hc013', 'hc014', 'hc015', 'hc016', 'hc017', 'hc018', 'hc019', 'hc020', \\\n",
    "#            'hc021', 'hc022', 'hc023', 'hc024', 'hc025', 'hc026', 'hc027', 'hc028', 'hc029', 'hc030', \\\n",
    "#            'hc031', 'hc032', 'hc033', 'hc034', 'hc035', 'hc036', 'hc037', 'hc038', 'hc041', 'hc042', \\\n",
    "#            'hc044', 'hc045']\n",
    "\n",
    "# subjlist = ['pp001', 'pp002', 'pp003', 'pp004', 'pp005', 'pp006', 'pp007', 'pp008',\\\n",
    "#             'pp009', 'pp010', 'pp011', 'pp012', 'pp013', 'pp014', 'pp015', 'pp016']\n",
    "\n",
    "subjlist = ['hc001']\n",
    "\n",
    "for subject in subjlist:\n",
    "    \n",
    "    #~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "    ### Define parameters.\n",
    "    #~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "\n",
    "#     subject = 'hc001'\n",
    "\n",
    "    ## Define acquisition parameters.    \n",
    "    n_acq = 228\n",
    "    tr = 1.75\n",
    "\n",
    "    ## Scrubbing parameters.\n",
    "    thresholds = [0.0, 0.5, 1.0, 1.5]\n",
    "\n",
    "    #~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "    ### Compute framewise displacement.\n",
    "    #~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "\n",
    "    ## Read motion data.\n",
    "    out_dir = '/autofs/space/lilli_004/users/DARPA-MSIT/%s/msit_001/001' %subject\n",
    "    mc = os.path.join(out_dir, 'fmcpr.mcdat')\n",
    "    mc = np.loadtxt(mc)[:,1:7]\n",
    "\n",
    "    ## Invert angular displacement.\n",
    "    fd = mc.copy()\n",
    "    fd[:,:3] = np.deg2rad(fd[:,:3]) \n",
    "    fd[:,:3] *= 50\n",
    "\n",
    "    ## Compute framewise displacement (See Power 2012, 2014).\n",
    "    fd = np.insert( np.abs( np.diff(fd, axis=0) ).sum(axis=1), 0, 0 )\n",
    "\n",
    "    #~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "    ### Compute motion regressors.\n",
    "    #~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "\n",
    "    ## Remove trends.\n",
    "    mc = detrend(mc, axis=0, type='constant')\n",
    "    mc = detrend(mc, axis=0, type='linear')\n",
    "    \n",
    "    ## Perform PCA.\n",
    "    pca = PCA(n_components=6)\n",
    "    mc = pca.fit_transform(mc)\n",
    "\n",
    "    ## Take only the number of components explaining 90% of the variance.\n",
    "    varexp = np.cumsum(pca.explained_variance_ratio_)\n",
    "    n_components = np.argmax(varexp >= 0.9) + 1\n",
    "    mc = mc[:,:n_components]\n",
    "\n",
    "    ## Save motion regressor.\n",
    "    f = os.path.join(out_dir, 'I-C.mc.txt')\n",
    "    np.savetxt(f, mc, fmt='%s')\n",
    "\n",
    "    #~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "    ### Write scrubbers.\n",
    "    #~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "\n",
    "    ## Define TR onsets.\n",
    "    tr_onsets = np.insert( np.cumsum( np.ones(n_acq - 1) * tr ), 0, 0 )\n",
    "\n",
    "    for threshold in thresholds:\n",
    "\n",
    "        ## Find threshold violations.\n",
    "        if not threshold: ix, = np.where(fd >= np.inf)\n",
    "        else: ix, = np.where(fd >= threshold)\n",
    "\n",
    "        ## Save.\n",
    "        f = os.path.join(out_dir, 'I-C.censor.%s.par' %threshold)\n",
    "        if len(ix): np.savetxt(f, tr_onsets[ix,np.newaxis], fmt='%s')\n",
    "\n",
    "    print 'Done.'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Decide on Censor Level\n",
    "This section will create a summary file for specified subjects and FD thresholds describing how many volumes (acquisitions) will be censored if the user chooses a specific FD threshold. The summary file is written to the fMRI folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-16T18:55:02.150465Z",
     "start_time": "2018-07-16T18:55:02.097192Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pandas import DataFrame, Series\n",
    "\n",
    "#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "### Define parameters.\n",
    "#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "\n",
    "## Define subjects.\n",
    "subjects = ['hc042']\n",
    "\n",
    "## Scrubbing parameters.\n",
    "thresholds = [0.0, 0.5, 1.0, 1.5]\n",
    "\n",
    "#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "### Make summary file.\n",
    "#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "\n",
    "columns = ['Subject'] + ['FD=%s' %fd for fd in thresholds]\n",
    "df = DataFrame([],columns=columns)\n",
    "\n",
    "for subject in subjects:\n",
    "    \n",
    "    ## Initialize.\n",
    "    info = Series()\n",
    "    info['Subject'] = subject\n",
    "    \n",
    "    ## Iteratively lookup and store information.\n",
    "    for fd in thresholds:\n",
    "        f = '/autofs/space/lilli_004/users/DARPA-MSIT/%s/msit_001/001/msit_EH_V1.censor.%s.par' %(subject,fd)\n",
    "        if os.path.isfile(f): info['FD=%s' %fd] = len(open(f,'r').readlines())\n",
    "        else: info['FD=%s' %fd] = 0\n",
    "            \n",
    "    ## Append information.\n",
    "    df = df.append(info, ignore_index=True)\n",
    "    \n",
    "## Save.\n",
    "df.to_csv('fmri/msit_censor_summary.csv', index=False)\n",
    "print 'Done.'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Run First-Level Scripts\n",
    "<br> >> cd /autofs/space/lilli_001/users/DARPA-Scripts/tutorials/darpa_msit_ecr_pipeline/scripts\n",
    "<br> >> source msit_I-C_1L_analysis.csh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Run Second-Level Scripts\n",
    "<br> >> cd /autofs/space/lilli_001/users/DARPA-Scripts/tutorials/darpa_msit_ecr_pipeline/scripts\n",
    "<br> >> source msit_I-C_2L_analysis.csh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: Visualize using MMVT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  },
  "nav_menu": {},
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "navigate_num": "#000000",
    "navigate_text": "#333333",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700",
    "sidebar_border": "#EEEEEE",
    "wrapper_background": "#FFFFFF"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "315px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": false,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_position": {
    "height": "36px",
    "left": "0px",
    "right": "1712px",
    "top": "52px",
    "width": "206px"
   },
   "toc_section_display": "none",
   "toc_window_display": true,
   "widenNotebook": false
  },
  "toc_position": {
   "height": "640px",
   "left": "0px",
   "right": "1156.8px",
   "top": "131px",
   "width": "379px"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
