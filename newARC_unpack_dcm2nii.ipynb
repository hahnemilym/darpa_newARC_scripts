{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-04T21:40:04.872477Z",
     "start_time": "2019-02-04T21:40:04.324830Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import copy\n",
    "import fnmatch\n",
    "import numpy as np\n",
    "import collections\n",
    "import pandas as pd\n",
    "from subprocess import call\n",
    "from itertools import repeat\n",
    "from itertools import dropwhile\n",
    "from IPython.display import display\n",
    "from pandas import read_csv, DataFrame, Index, MultiIndex"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set up Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-04T21:40:05.115276Z",
     "start_time": "2019-02-04T21:40:05.106280Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path = '/autofs/space/lilli_001/users'\n",
    "NARC = os.path.join('%s/DARPA-ARC_RER' % path)\n",
    "NARC_analysis = os.path.join('%s/DARPA-Scripts/tutorials/darpa_pipelines_EH/darpa_newARC_scripts/params' % path)\n",
    "\n",
    "scan_list=[]\n",
    "subjs_list=[]\n",
    "\n",
    "unpack_log='unpack.log'\n",
    "raw_cfg= 'cfg_raw.txt'\n",
    "new_cfg='cfg.txt'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Subject and Scan lists"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Import *SPECIFIC* scans from BOURGET | FIRST, manually modify subjlist.txt, scan.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-04T21:40:07.084877Z",
     "start_time": "2019-02-04T21:40:07.070797Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_scans_subjects(analysis_path,scan_list,subjs_list):\n",
    "    with open('%s/subjlist.txt' % analysis_path ,'r') as sublist, \\\n",
    "    open('%s/scan.txt' % analysis_path ,'r') as scanlist:\n",
    "        for subject,scan in zip(sublist,scanlist):\n",
    "            subjs_list.append(subject.strip())\n",
    "            scan_list.append(scan.strip())\n",
    "    return\n",
    "\n",
    "get_scans_subjects(NARC_analysis,scan_list,subjs_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# unpackdcmsdir P.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-04T21:40:18.928343Z",
     "start_time": "2019-02-04T21:40:18.916984Z"
    }
   },
   "outputs": [],
   "source": [
    "def unpacksdcmdir_step1(analysis_path,scan_list,subjs_list,raw_data_path):\n",
    "    with open('%s/unpacksdcmdir_step1.csh' % analysis_path ,'w') as unpacksdcmdir_1:\n",
    "        for scan,subject in zip(scan_list,subjs_list):\n",
    "            unpacksdcmdir_1.write('unpacksdcmdir -src %s -targ %s/%s/RAW -scanonly %s/%s/RAW/%s;\\n' \\\n",
    "            % (scan, raw_data_path, subject, raw_data_path, subject, raw_cfg))\n",
    "        print \"Next: manually source unpacksdcmdir_step1.csh\"\n",
    "    return\n",
    "\n",
    "unpacksdcmdir_step1(NARC_analysis,scan_list,subjs_list,NARC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Configuration File"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract cfg data from unpack.log\n",
    "##### NOTE: unpack.log is used in lieu of cfg_raw.txt (from the first unpackdcmsdir step) to generate cfg.txt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-04T21:32:02.714827Z",
     "start_time": "2019-02-04T21:32:02.690196Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cfg_data={'a':[],'b':[],'c':[],'d':[]}\n",
    "\n",
    "def extract_unpack_data(raw_data_path,subjs_list,unpack_log,cfg_data): \n",
    "    for subject in subjs_list:\n",
    "        infile=os.path.join(raw_data_path,subject,'RAW',unpack_log)\n",
    "        with open(infile,'r') as in_txt:\n",
    "            for line in in_txt:\n",
    "                if 'ok' in line:\n",
    "                    c=line.strip().split()\n",
    "                    n=str(c[0])\n",
    "                    scan=str(c[1])\n",
    "                    num=str(c[7])\n",
    "                    cfg_data['a'].append(n)\n",
    "                    dicom='DICOM'\n",
    "                    cfg_data['b'].append(scan)\n",
    "                    cfg_data['c'].append(dicom)\n",
    "                    cfg_data['d'].append(num)\n",
    "    return\n",
    "\n",
    "extract_unpack_data(NARC,subjs_list,unpack_log,cfg_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save raw cfg and generate new cfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-04T20:02:58.437903Z",
     "start_time": "2019-02-04T20:02:58.425958Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def format_cfg(raw_data_path,subjs_list,raw_cfg,new_cfg,cfg_data):\n",
    "    for subject in subjs_list:\n",
    "        orig_cfg_subdir = os.path.join(raw_data_path,\"%s/RAW/cfg.txt\" % subject.rstrip(' \\n'))\n",
    "        with open(orig_cfg_subdir, 'w') as form_cfg:\n",
    "            for a,b,c,d in zip(cfg_data['a'],cfg_data['b'],cfg_data['c'],cfg_data['d']):\n",
    "                form_cfg.write('\\t'.join([a,b,c,d]) + '\\n')\n",
    "    return\n",
    "\n",
    "format_cfg(NARC,subjs_list,raw_cfg,new_cfg,cfg_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# unpackdcmsdir P.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-04T20:02:59.395764Z",
     "start_time": "2019-02-04T20:02:59.385565Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def unpacksdcmdir_step1(analysis_path,scan_list,subjs_list,raw_data_path): \n",
    "    with open('%s/unpacksdcmdir_step2.csh' % analysis_path ,'w') as unpacksdcmdir_2, \\\n",
    "    open('%s/subjlist.txt' % analysis_path ,'r') as sublist:\n",
    "        for scan,subject in zip(scan_list,subjs_list):    \n",
    "            subdir = os.path.join(raw_data_path,\"%s/RAW/cfg.txt\" % subject.rstrip(' \\n'))\n",
    "            unpacksdcmdir_2.write('unpacksdcmdir -src %s -targ %s/%s/RAW -fsfast -cfg %s; \\n'\\\n",
    "            % (scan.rstrip(' \\n'), raw_data_path.rstrip(' \\n'), subject.rstrip(' \\n'), subdir))\n",
    "        print \"Next: source unpacksdcmdir_step2.csh\"\n",
    "    return\n",
    "\n",
    "unpacksdcmdir_step1(NARC_analysis,scan_list,subjs_list,NARC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# mri_convert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-04T21:32:35.612331Z",
     "start_time": "2019-02-04T21:32:35.523905Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dcm2nii='mri_dcm2nii_converter.csh'\n",
    "\n",
    "path = '/autofs/space/lilli_001/users'\n",
    "NARC = os.path.join('%s/DARPA-ARC_RER' % path)\n",
    "NARC_analysis = os.path.join('%s/DARPA-Scripts/tutorials/darpa_pipelines_EH/darpa_newARC_scripts/params' % path)\n",
    "\n",
    "def mri_dcm2nii(analysis_path, mri_converter, subjs_list,cfg_data):\n",
    "    with open('%s/%s' % (analysis_path, mri_converter),'w') as scanlist:\n",
    "        for subject in subjs_list:\n",
    "            for scan,dcm in zip(cfg_data['b'],cfg_data['d']):   \n",
    "                cwd=os.path.join(NARC,subject,'RAW',scan)\n",
    "                for root, dirs, files in os.walk(cwd,topdown=False):\n",
    "                    if dcm in os.listdir(root):\n",
    "                        s=os.path.join(root,dcm)\n",
    "                        scanlist.write('mri_convert %s %s/%s.nii; \\n' % (s,root,scan))\n",
    "    return\n",
    "\n",
    "mri_dcm2nii(NARC_analysis, dcm2nii, subjs_list,cfg_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Additional Functions (OPTIONAL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-07T20:59:00.353068Z",
     "start_time": "2018-02-07T20:58:59.907128Z"
    }
   },
   "source": [
    "### Read Configuration File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-04T21:14:23.052266Z",
     "start_time": "2019-02-04T21:14:23.045116Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# def read_cfg(path,subjid,doc): \n",
    "#     insert=os.path.join(path, subjid, doc)\n",
    "#     doc=open(insert,'r' )\n",
    "#     print doc.read()\n",
    "    \n",
    "# read_cfg('/autofs/space/will_001/users/TLC/pilot_1st20subj/MGH/','020043MR01','unpack.log')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loop to search for first DICOM in series (if not known from cfg file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-04T21:14:23.998276Z",
     "start_time": "2019-02-04T21:14:23.989319Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# for subject in subjs_list:\n",
    "#     bold_path= '%s/mri/%s/%s' % (NARC, subject, newARC_BOLD)\n",
    "#     d1dir= os.listdir(bold_path)\n",
    "#     for subdir in d1dir:\n",
    "#         if subdir.startswith('0'):\n",
    "#             subzir=os.path.join(bold_path,subdir)\n",
    "#             for root, dirs, files in os.walk(os.path.join(bold_path,subdir)):\n",
    "#                 for filename in fnmatch.filter(files, \"*ARC_BOLD_RER*\"):\n",
    "#                     zir=sorted(os.listdir(os.path.join(bold_path,subdir)))\n",
    "#                     if zir[0].startswith('MR'):\n",
    "#                         inp=os.path.join(bold_path,subdir,zir[0])\n",
    "#                         zirz.append(inp)\n",
    "#                     elif zir[1].startswith('MR'):\n",
    "#                         inp=os.path.join(bold_path,subdir,zir[1])\n",
    "#                         zirz.append(inp)\n",
    "                        \n",
    "# with open('%s/%s' % (NARC_analysis, mri_converter),'w') as scanlist:\n",
    "# #     del zirz[55:58]\n",
    "#     for z,subject in zip(zirz,subjs_list):\n",
    "#         print z\n",
    "#         print subject\n",
    "#         subject=subject.lower()[:-3]\n",
    "#         scanlist.write('mri_convert %s %s/%s/msit_bsm/func/msit.%s.func.nii \\n' % (z,indiv_pth,subject,subject))\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import *ALL* scans from BOURGET\n",
    "##### i.e. Automatically generate FINDSESS.txt, subjlist.txt, scan.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-04T21:14:25.067400Z",
     "start_time": "2019-02-04T21:14:25.060319Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#----------------------------#\n",
    "# Generate Step 1,2 C shells\n",
    "#----------------------------#\n",
    "# os.system('cd %s; touch subjlist.txt scan.txt unpacksdcmdir_step1.csh unpacksdcmdir_step2.csh' % NARC_analysis)\n",
    "\n",
    "#os.system('findsession -p res > %s/FINDSESS.txt' % NARC_analysis)\n",
    "\n",
    "# def get_scans_subjects(path):\n",
    "#     with open('%s/FINDSESS.txt' % path ,'r') as in_txt, \\\n",
    "#         open('%s/subjlist.txt' % path ,'w') as sublist, \\\n",
    "#         open('%s/scan.txt' % path ,'w') as scanlist:\n",
    "#         for line in in_txt:\n",
    "#                 if 'SUBJECT' in line:\n",
    "#                     sub=line.strip('SUBJECT:  ')\n",
    "#                     sublist.write('%s \\n' % sub.strip())\n",
    "#                     subject_list.append(sub)\n",
    "#                 elif 'PATH' in line:\n",
    "#                     scan=line.strip('PATH   :')\n",
    "#                     scanlist.write('%s \\n' % scan.strip())\n",
    "#                     transfer_scanlist.append(sub)\n",
    "#     return\n",
    "#\n",
    "# get_scans_subjects(NARC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fix this cell to source FreeSurfer6 and enable C shell scripting in Jupyter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-04T21:14:26.162111Z",
     "start_time": "2019-02-04T21:14:26.157474Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# from subprocess import call\n",
    "# import os\n",
    "\n",
    "# call(['cd %s' % NARC_analysis],shell=True) \n",
    "# call(['source /usr/local/freesurfer/nmr-stable60-env'],shell=True)\n",
    "# call(['source %s/unpacksdcmdir_step1.csh' % NARC_analysis],shell=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DICOM to NIFTI - ARCHIVE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-04T21:14:27.397001Z",
     "start_time": "2019-02-04T21:14:27.388882Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# scan_list=['MEMPRAGE','BOLD']\n",
    "\n",
    "# path=[]\n",
    "# output=[]\n",
    "\n",
    "# def dicom2nii_get_path(path):\n",
    "#     for subject in subject_list:\n",
    "#         if subject in os.listdir(path):\n",
    "#             for scan in scan_list:\n",
    "#                 if scan in os.listdir(os.path.join(path,subject)):\n",
    "#                     insert=os.path.join(path, subject, scan)\n",
    "#                     subdir=os.listdir(insert)\n",
    "#                     for item in subdir:\n",
    "#                         if item.startswith('0'):\n",
    "#                             insert2=os.path.join(path, subject, scan, item)\n",
    "#                             dicom1=os.listdir(insert2)[0]\n",
    "#                             insert3=os.path.join(path, subject, scan, item, dicom1)\n",
    "#                             save_me=output.append(insert3)  \n",
    "#     return\n",
    "\n",
    "# dicom2nii_get_path('%s' % path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "navigate_num": "#000000",
    "navigate_text": "#333333",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700",
    "sidebar_border": "#EEEEEE",
    "wrapper_background": "#FFFFFF"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "187px",
    "width": "388px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
