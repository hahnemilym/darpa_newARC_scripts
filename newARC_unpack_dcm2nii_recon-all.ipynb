{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# newARC | unpackdcmsdir | mri_convert | recon-all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-05T22:56:40.175808Z",
     "start_time": "2019-02-05T22:56:39.422928Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import copy\n",
    "import fnmatch\n",
    "import numpy as np\n",
    "import collections\n",
    "import pandas as pd\n",
    "from subprocess import call\n",
    "from itertools import repeat\n",
    "from itertools import dropwhile\n",
    "from IPython.display import display\n",
    "from pandas import read_csv, DataFrame, Index, MultiIndex"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set up Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-05T22:56:42.080574Z",
     "start_time": "2019-02-05T22:56:42.063561Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path = '/autofs/space/lilli_001/users'\n",
    "NARC = os.path.join('%s/DARPA-newARC-TRANSFER' % path)\n",
    "NARC_analysis = os.path.join('%s/DARPA-Scripts/tutorials/darpa_pipelines_EH/darpa_newARC_scripts/params' % path)\n",
    "recon_path='/autofs/space/lilli_001/users/DARPA-newARC-RECONS'\n",
    "\n",
    "unpack_log='unpack.log'\n",
    "raw_cfg= 'cfg_raw.txt'\n",
    "new_cfg='cfg.txt'\n",
    "dcm2nii_anat='mri_dcm2nii_anat_converter.csh'\n",
    "dcm2nii_func='mri_dcm2nii_func_converter.csh'\n",
    "T1='MEMPRAGE_4e_p2_1mm_iso'\n",
    "recon_all='recon_all_2-5-19.csh'\n",
    "fs_func_nii='f'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Subject and Scan lists"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Import *SPECIFIC* scans from BOURGET | FIRST, manually modify subjlist.txt, scan.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-05T22:56:57.415951Z",
     "start_time": "2019-02-05T22:56:57.406873Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##----------------------------------------##\n",
    "## Generate Subject and Scan lists from .txt\n",
    "##----------------------------------------##\n",
    "\n",
    "# def get_scans_subjects(analysis_path,scan_list,subjs_list):\n",
    "#     with open('%s/subjlist.txt' % analysis_path ,'r') as sublist, \\\n",
    "#     open('%s/scan.txt' % analysis_path ,'r') as scanlist:\n",
    "#         for subject,scan in zip(sublist,scanlist):\n",
    "#             subjs_list.append(subject.strip())\n",
    "#             scan_list.append(scan.strip())\n",
    "#     return\n",
    "# get_scans_subjects(NARC_analysis,scan_list,subjs_list)\n",
    "\n",
    "##----------------------------------------##\n",
    "## Manually Specify Subject and Scan lists\n",
    "##----------------------------------------##\n",
    "# subjs_list=[]\n",
    "# scan_list=[]\n",
    "\n",
    "subjs_list=['newARC_001','newARC_004','newARC_005','newARC_010','newARC_011','newARC_014','newARC_015','newARC_016','newARC_017','newARC_018','newARC_020']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-04T22:01:55.677643Z",
     "start_time": "2019-02-04T22:01:55.673907Z"
    }
   },
   "source": [
    "# Generate Directory Structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-05T00:04:21.105440Z",
     "start_time": "2019-02-05T00:04:21.100403Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import subprocess\n",
    "for subject in subjs_list:\n",
    "    for root, dirs, files in os.walk(NARC,topdown=False):\n",
    "        if subject not in dirs:\n",
    "            subprocess.check_call('mkdir -p %s/%s/RAW' % (NARC,subject),shell=True) \n",
    "        elif subject in dirs:\n",
    "            print \"Duplicate ID: Manually unpack %s\" % subject"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# unpackdcmsdir P.1\n",
    "##### unpacksdcmdir -src SCAN -targ OUTPUT_DIR -scanonly CFG_RAW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-05T00:04:24.764663Z",
     "start_time": "2019-02-05T00:04:24.759214Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def unpacksdcmdir_step1(analysis_path,scan_list,subjs_list,raw_data_path):\n",
    "    with open('%s/unpacksdcmdir_step1.csh' % analysis_path ,'w') as unpacksdcmdir_1:\n",
    "        for scan,subject in zip(scan_list,subjs_list):\n",
    "            unpacksdcmdir_1.write('unpacksdcmdir -src %s -targ %s/%s/RAW -scanonly %s/%s/RAW/%s;\\n' \\\n",
    "            % (scan, raw_data_path, subject, raw_data_path, subject, raw_cfg))\n",
    "    return\n",
    "\n",
    "unpacksdcmdir_step1(NARC_analysis,scan_list,subjs_list,NARC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Configuration File"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract cfg_raw.txt + write cfg.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-05T00:23:55.727944Z",
     "start_time": "2019-02-05T00:23:55.691605Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def extract_unpack_data(raw_data_path,subjs_list,raw_cfg,new_cfg): \n",
    "    for subject in subjs_list:\n",
    "        cfg_data={'a':[],'b':[],'c':[],'d':[]}\n",
    "        infile=os.path.join(raw_data_path,subject,'RAW',raw_cfg)\n",
    "        with open(infile,'r') as in_txt:\n",
    "            for line in in_txt:\n",
    "                if 'ok' in line:\n",
    "                    c=line.strip().split()\n",
    "                    n=str(c[0])\n",
    "                    scan=str(c[1])\n",
    "                    num=str(c[7])\n",
    "                    cfg_data['a'].append(n)\n",
    "                    dicom='DICOM'\n",
    "                    cfg_data['b'].append(scan)\n",
    "                    cfg_data['c'].append(dicom)\n",
    "                    cfg_data['d'].append(num)\n",
    "            orig_cfg_subdir = os.path.join(raw_data_path,\"%s/RAW/cfg.txt\" % subject.rstrip(' \\n'))\n",
    "            with open(orig_cfg_subdir, 'w') as form_cfg:\n",
    "                for a,b,c,d in zip(cfg_data['a'],cfg_data['b'],cfg_data['c'],cfg_data['d']):\n",
    "                    form_cfg.write('\\t'.join([a,b,c,d]) + '\\n')\n",
    "    return\n",
    "\n",
    "extract_unpack_data(NARC,subjs_list,unpack_log,new_cfg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# unpackdcmsdir P.2\n",
    "##### unpacksdcmdir -src SCAN -targ OUTPUT_DIR -fsfast -scanonly CFG_FORMATTED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-05T00:25:47.463843Z",
     "start_time": "2019-02-05T00:25:47.450798Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def unpacksdcmdir_step1(analysis_path,scan_list,subjs_list,raw_data_path): \n",
    "    with open('%s/unpacksdcmdir_step2.csh' % analysis_path ,'w') as unpacksdcmdir_2, \\\n",
    "    open('%s/subjlist.txt' % analysis_path ,'r') as sublist:\n",
    "        for scan,subject in zip(scan_list,subjs_list):    \n",
    "            subdir = os.path.join(raw_data_path,\"%s/RAW/cfg.txt\" % subject.rstrip(' \\n'))\n",
    "            unpacksdcmdir_2.write('unpacksdcmdir -src %s -targ %s/%s/RAW -fsfast -cfg %s; \\n'\\\n",
    "            % (scan.rstrip(' \\n'), raw_data_path.rstrip(' \\n'), subject.rstrip(' \\n'), subdir))\n",
    "    return\n",
    "\n",
    "unpacksdcmdir_step1(NARC_analysis,scan_list,subjs_list,NARC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# mri_convert\n",
    "##### Before running this step, make sure specified subject directories have newARC_### nomenclature - or this will not work"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## mri_convert | anat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-05T04:48:34.437520Z",
     "start_time": "2019-02-05T04:48:34.245007Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scans_array=['AAScout','fieldmap_2mm_iso','localizer','MEMPRAGE_4e_p2_1mm_iso','SNR_Map']\n",
    "\n",
    "def mri_dcm2nii_structural(raw_data_path,analysis_path, mri_converter, subjs_list):\n",
    "    with open('%s/%s' % (analysis_path, mri_converter),'w') as scanlist:\n",
    "        for subject in subjs_list:\n",
    "            max_scans=[]\n",
    "            for scan in scans_array:\n",
    "                dir_n=[]\n",
    "                dir_length=[]\n",
    "                subdir=[]\n",
    "                cwd=os.path.join(raw_data_path,subject,'RAW',scan)\n",
    "                for root, dirs, files in os.walk(cwd,topdown=False):\n",
    "                    for dir in dirs:\n",
    "                        temp_dir=os.path.join(root,dir)\n",
    "                        dl=len(os.listdir(temp_dir))\n",
    "                        dir_length.append(dl)\n",
    "                        dir_n.append(temp_dir)\n",
    "                x=max(dir_length)\n",
    "                subdir_ix=dir_length.index(x)\n",
    "                subdir=dir_n[subdir_ix]\n",
    "                sx=os.path.join(temp_dir,subdir)\n",
    "                max_scans.append(subdir)\n",
    "            for sc in max_scans:\n",
    "                dcm=sorted(os.listdir(sc))[0]\n",
    "                SCAN=sc[59:-4]\n",
    "                out_path=os.path.join(raw_data_path,subject,'RAW',SCAN)\n",
    "                scanlist.write('mri_convert %s/%s %s/%s.nii; \\n' % (sc,dcm,out_path,SCAN))\n",
    "    return\n",
    "\n",
    "mri_dcm2nii_structural(NARC,NARC_analysis, dcm2nii_anat, subjs_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## mri_convert | func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-05T04:49:51.714296Z",
     "start_time": "2019-02-05T04:49:51.252397Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "new_arc_scans='ARC_BOLD_RER_SMS3_PAT2_2mm_iso_1p75'\n",
    "\n",
    "def mri_dcm2nii_functional(raw_data_path,analysis_path, mri_converter, subjs_list,fs_func_nii):\n",
    "    with open('%s/%s' % (analysis_path, mri_converter),'w') as scanlist:\n",
    "        for subject in subjs_list:\n",
    "            fwd=os.path.join(raw_data_path,subject,'RAW', new_arc_scans)\n",
    "            for root, dirs, files in os.walk(fwd,topdown=True):\n",
    "                blocks=['block1','block2','block3']\n",
    "                for d,b in zip(dirs,blocks):\n",
    "                    os.system('mkdir %s/%s' % (fwd,b))\n",
    "                    dcm_dir=os.path.join(fwd,d)\n",
    "                    f_convert=os.path.join(dcm_dir,sorted(os.listdir(dcm_dir))[0])\n",
    "                    out_path=os.path.join(fwd,b)\n",
    "                    scanlist.write('mri_convert %s %s/%s.nii; \\n' % (f_convert,out_path,fs_func_nii))\n",
    "    return\n",
    "\n",
    "mri_dcm2nii_functional(NARC,NARC_analysis, dcm2nii_func, subjs_list,fs_func_nii)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Configure recon-all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-05T23:36:23.183724Z",
     "start_time": "2019-02-05T23:36:23.167053Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def config_recon_all(raw_data_path,analysis_path,recon_script,subjs_list,T1,recon_path):\n",
    "    with open('%s' % os.path.join(analysis_path,recon_script),'w') as recon_all_list:\n",
    "        for subject in subjs_list:\n",
    "#             recon_all_list.write(\"source /usr/local/freesurfer/nmr-stable60-env;\\n\")\n",
    "            recon_all_list.write(\"setenv SUBJECTS_DIR %s;\\n\" % recon_path) \n",
    "            recon_all_list.write(\"cd $SUBJECTS_DIR;\\n\")\n",
    "            recon_all_list.write(\"mri_concat --rms %s/%s/RAW/%s/%s.nii --o %s/%s/RAW/%s/%s.nii;\\n\" % (raw_data_path,subject,T1,T1,raw_data_path,subject,T1,T1)) \n",
    "            recon_all_list.write(\"recon-all -i %s/%s/RAW/%s/%s.nii -subjid %s;\\n\" % (raw_data_path,subject,T1,T1,subject)) \n",
    "            recon_all_list.write(\"recon-all -all -subjid %s;\\n\\n\" % subject) \n",
    "    return\n",
    "                                 \n",
    "config_recon_all(NARC,NARC_analysis,recon_all,subjs_list,T1,recon_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submit job(s) to cluster"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "1. setenv NARC_analysis /autofs/space/lilli_001/users/DARPA-Scripts/tutorials/darpa_pipelines_EH/darpa_newARC_scripts/params/\n",
    "2. cd ${NARC_analysis}\n",
    "3. ssh launchpad\n",
    "4. Submit job(s): pbsubmit -c \"$command\" -m $user -n $CPUs\n",
    "\n",
    "helpful commands\n",
    "qstat | grep -w emh89\n",
    "qdel ######.launchpad.nmr.mgh.harvard.edu\n",
    "cat /pbs/<username>/pbsjob_2.status"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unpack Scans Manually"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "1. unpacksdcmdir -src $BOURGET_PATH -targ $RAW_SCANS_DIR -scanonly $CFG_RAW\n",
    "\n",
    "2. configure cfg.txt\n",
    "\n",
    "3. unpacksdcmdir -src $BOURGET_PATH -targ $RAW_SCANS_DIR -fsfast -cfg $CONFIGURED_CFG"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Additional Functions (OPTIONAL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-07T20:59:00.353068Z",
     "start_time": "2018-02-07T20:58:59.907128Z"
    }
   },
   "source": [
    "### Read Configuration File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-04T21:14:23.052266Z",
     "start_time": "2019-02-04T21:14:23.045116Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# def read_cfg(path,subjid,doc): \n",
    "#     insert=os.path.join(path, subjid, doc)\n",
    "#     doc=open(insert,'r' )\n",
    "#     print doc.read()\n",
    "    \n",
    "# read_cfg('/autofs/space/will_001/users/TLC/pilot_1st20subj/MGH/','020043MR01','unpack.log')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loop to search for first DICOM in series (if not known from cfg file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-04T21:14:23.998276Z",
     "start_time": "2019-02-04T21:14:23.989319Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# for subject in subjs_list:\n",
    "#     bold_path= '%s/mri/%s/%s' % (NARC, subject, newARC_BOLD)\n",
    "#     d1dir= os.listdir(bold_path)\n",
    "#     for subdir in d1dir:\n",
    "#         if subdir.startswith('0'):\n",
    "#             subzir=os.path.join(bold_path,subdir)\n",
    "#             for root, dirs, files in os.walk(os.path.join(bold_path,subdir)):\n",
    "#                 for filename in fnmatch.filter(files, \"*ARC_BOLD_RER*\"):\n",
    "#                     zir=sorted(os.listdir(os.path.join(bold_path,subdir)))\n",
    "#                     if zir[0].startswith('MR'):\n",
    "#                         inp=os.path.join(bold_path,subdir,zir[0])\n",
    "#                         zirz.append(inp)\n",
    "#                     elif zir[1].startswith('MR'):\n",
    "#                         inp=os.path.join(bold_path,subdir,zir[1])\n",
    "#                         zirz.append(inp)\n",
    "                        \n",
    "# with open('%s/%s' % (NARC_analysis, mri_converter),'w') as scanlist:\n",
    "# #     del zirz[55:58]\n",
    "#     for z,subject in zip(zirz,subjs_list):\n",
    "#         print z\n",
    "#         print subject\n",
    "#         subject=subject.lower()[:-3]\n",
    "#         scanlist.write('mri_convert %s %s/%s/msit_bsm/func/msit.%s.func.nii \\n' % (z,indiv_pth,subject,subject))\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import *ALL* scans from BOURGET\n",
    "##### i.e. Automatically generate FINDSESS.txt, subjlist.txt, scan.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-04T21:14:25.067400Z",
     "start_time": "2019-02-04T21:14:25.060319Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#----------------------------#\n",
    "# Generate Step 1,2 C shells\n",
    "#----------------------------#\n",
    "# os.system('cd %s; touch subjlist.txt scan.txt unpacksdcmdir_step1.csh unpacksdcmdir_step2.csh' % NARC_analysis)\n",
    "\n",
    "#os.system('findsession -p res > %s/FINDSESS.txt' % NARC_analysis)\n",
    "\n",
    "# def get_scans_subjects(path):\n",
    "#     with open('%s/FINDSESS.txt' % path ,'r') as in_txt, \\\n",
    "#         open('%s/subjlist.txt' % path ,'w') as sublist, \\\n",
    "#         open('%s/scan.txt' % path ,'w') as scanlist:\n",
    "#         for line in in_txt:\n",
    "#                 if 'SUBJECT' in line:\n",
    "#                     sub=line.strip('SUBJECT:  ')\n",
    "#                     sublist.write('%s \\n' % sub.strip())\n",
    "#                     subject_list.append(sub)\n",
    "#                 elif 'PATH' in line:\n",
    "#                     scan=line.strip('PATH   :')\n",
    "#                     scanlist.write('%s \\n' % scan.strip())\n",
    "#                     transfer_scanlist.append(sub)\n",
    "#     return\n",
    "#\n",
    "# get_scans_subjects(NARC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fix this cell to source FreeSurfer6 and enable C shell scripting in Jupyter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-04T21:14:26.162111Z",
     "start_time": "2019-02-04T21:14:26.157474Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# from subprocess import call\n",
    "# import os\n",
    "\n",
    "# call(['cd %s' % NARC_analysis],shell=True) \n",
    "# call(['source /usr/local/freesurfer/nmr-stable60-env'],shell=True)\n",
    "# call(['source %s/unpacksdcmdir_step1.csh' % NARC_analysis],shell=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DICOM to NIFTI - ARCHIVE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-04T21:14:27.397001Z",
     "start_time": "2019-02-04T21:14:27.388882Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# scan_list=['MEMPRAGE','BOLD']\n",
    "\n",
    "# path=[]\n",
    "# output=[]\n",
    "\n",
    "# def dicom2nii_get_path(path):\n",
    "#     for subject in subject_list:\n",
    "#         if subject in os.listdir(path):\n",
    "#             for scan in scan_list:\n",
    "#                 if scan in os.listdir(os.path.join(path,subject)):\n",
    "#                     insert=os.path.join(path, subject, scan)\n",
    "#                     subdir=os.listdir(insert)\n",
    "#                     for item in subdir:\n",
    "#                         if item.startswith('0'):\n",
    "#                             insert2=os.path.join(path, subject, scan, item)\n",
    "#                             dicom1=os.listdir(insert2)[0]\n",
    "#                             insert3=os.path.join(path, subject, scan, item, dicom1)\n",
    "#                             save_me=output.append(insert3)  \n",
    "#     return\n",
    "\n",
    "# dicom2nii_get_path('%s' % path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "navigate_num": "#000000",
    "navigate_text": "#333333",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700",
    "sidebar_border": "#EEEEEE",
    "wrapper_background": "#FFFFFF"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "187px",
    "width": "388px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
